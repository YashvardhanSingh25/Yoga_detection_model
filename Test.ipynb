{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b608d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"yoga_video_classifierV2.h5\")\n",
    "\n",
    "# Must match training class order\n",
    "class_names = ['Balassana', 'Bhungassan', 'Padmasan', 'Parvatassan', 'Savasan', 'LeftTrikonasanas', 'RightTrikonasanas']\n",
    "\n",
    "\n",
    "# ðŸ§± 1. Use existing extraction function\n",
    "def extract_frames_single_video(video_path, output_dir='temp_frames', frame_rate=30):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_rate == 0:\n",
    "            frame_name = f\"{uuid.uuid4().hex}.jpg\"\n",
    "            frame_path = os.path.join(output_dir, frame_name)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return saved_count\n",
    "\n",
    "\n",
    "# ðŸ§  2. Predict from frames\n",
    "def predict_from_frames(frame_dir, img_size=(224, 224)):\n",
    "    predictions = []\n",
    "\n",
    "    for fname in os.listdir(frame_dir):\n",
    "        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(frame_dir, fname)\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, img_size)\n",
    "        image = img_to_array(image) / 255.0\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        pred = model.predict(image, verbose=0)\n",
    "        predicted_class = np.argmax(pred)\n",
    "        predictions.append(predicted_class)\n",
    "\n",
    "    if not predictions:\n",
    "        return \"No frames processed.\"\n",
    "\n",
    "    most_common_class = Counter(predictions).most_common(1)[0][0]\n",
    "    return class_names[most_common_class]\n",
    "\n",
    "\n",
    "# ðŸ§ª 3. Full prediction pipeline\n",
    "def predict_video_class(video_path, frame_rate=30):\n",
    "    temp_dir = \"temp_frames\"\n",
    "\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "    frame_count = extract_frames_single_video(video_path, output_dir=temp_dir, frame_rate=frame_rate)\n",
    "    print(f\"Extracted {frame_count} frames from video.\")\n",
    "\n",
    "    result = predict_from_frames(temp_dir)\n",
    "\n",
    "    shutil.rmtree(temp_dir)  # Clean up\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fa599f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"Dataset\\Padmasan\\Padmasan2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb49da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 12 frames from video.\n",
      "Predicted Asana: Parvatassan\n"
     ]
    }
   ],
   "source": [
    "# video_file = \"test_video.mp4\"\n",
    "predicted_class = predict_video_class(video_path, frame_rate=30)\n",
    "print(\"Predicted Asana:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e79a1139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 11 frames from video.\n",
      "Predicted Asana: Parvatassan\n"
     ]
    }
   ],
   "source": [
    "video_path = r\"Dataset\\Padmasan\\Padmasan3.mp4\"\n",
    "# video_file = \"test_video.mp4\"\n",
    "predicted_class = predict_video_class(video_path, frame_rate=30)\n",
    "print(\"Predicted Asana:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f1811d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 9 frames from video.\n",
      "Predicted Asana: Balassana\n"
     ]
    }
   ],
   "source": [
    "video_path = r\"Dataset\\Balassana\\Balassana18.mp4\"\n",
    "# video_file = \"test_video.mp4\"\n",
    "predicted_class = predict_video_class(video_path, frame_rate=30)\n",
    "print(\"Predicted Asana:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365bd1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972d0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
